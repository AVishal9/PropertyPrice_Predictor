---
title: "Predicting Real Estate Prices in the United States: A Data-Driven Approach"
output: pdf_document
author: 
 - name: Maanya Bagga
   affiliation: (23-451-164)
 - name: Vishal Varma Alluri
   affiliation: (19-876-093)
 - name: Rakesh Varma Addada
   affiliation: (19-876-135)
date: "2024-12-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The real estate market is inherently dynamic and prone to fluctuations making it a critical area of focus for diverse range of stakeholders. These include investors looking to maximise returns, employees working within the sector, tenants, property management teams maintaining assets etc. The primary objective of this project was to develop a  robust predictive model to accurately estimate real estate prices leveraging machine learning techniques.The application of machine learning in the real estate sector offers several advantages over traditional methods, like Comparable Market Analysis (CMA), which are often limited to small-scale predictive tasks.

**Relevance of machine learning models in real estate sector**

- Ability to handle large dataset - While traditional methods like CMA are effective for localized and small-scale price predictions, they struggle to process and analyze the vast volumes of data generated in the real estate sector.

- Modeling Complex Relationships - Real estate prices are influenced by numerous factors, including location, property features, market trends, and economic conditions. Machine learning techniques excel at identifying and modeling complex, non-linear interactions between these variables, which traditional methods often fail to capture

- Improved Accuracy and Insights - Machine learning models can provide more accurate predictions and deeper insights by continuously learning from new data.

In this project, five different machine learning models were trained to predict real estate prices based on a predefined set of features.Each model was evaluated using standardized error metrics, such as Root Mean Square Error (RMSE) and R-squared to ensure a comprehensive assessment of their predictive performance.


## About the Dataset

#### Source and Features

The original dataset was sourced from kaggle.It was a csv file consisting of 2,226,382 observation representing real estate listings in the United States. The data is categorized by various attributes, including state, city, and ZIP code.The dataset had 12 features in total out of which 6 variables were categorical columns - **Brokered by** , **Status**, **Street**, **city**, **state** and **zip_code**. Brokered by and street were numerically encoded for privacy purposes. Our target variable **Price** represents the sale price of a property in dollars.
It includes **house_size** which represents size of the house in square feet, representing the living space or building area while **acre_lot** refers to the total land area of the property. In case the property has been sold previously, the column **previously sold date** includes a date, otherwise it is Null.The data on real estate was originally parsed from Realtor.com, a prominent real estate listing website in the USA.


#### Data Cleaning 

**Before Smapling**

**Sampling**


**After Sampling**
Before proceeding with sampling, we already excluded observations lying outside the 99th percentile to mitigate the impact of extreme outliers. Despite this preprocessing step, certain variables in the dataset exhibited positive skewness:

**Price and House Size:**
The means of these variables were slightly higher than their respective medians, indicating mild positive skewness.This skewness was attributed to the presence of luxury properties with prices ranging between $3,000 and $4,000 per square foot.
**Land Size:**
The mean and median values for land size showed a significant disparity, highlighting substantial skewness in this variable.To address this, we created a subset by excluding observations that significantly deviated from the mean, using a threshold based on a specific number of standard deviations. However, even in this subset, the variables retained a right-tailed distribution.

Given this, we decided to retain the original dataset as it provided a balanced representation of the population, including the high-end luxury properties, which are an integral part of the real estate market.

```{r pressure, echo=FALSE}
plot(pressure)
```


## Data Exploration and Visualisation



## Models

### Model: Linear Regression

Linear regression was chosen as the baseline model for this project due to its simplicity and effectiveness, as evidenced by the literature. It is widely recognized in the real estate domain for its low prediction error when capturing relationships between features and target variable i.e. price. However, despite its merits, this model was not a perfect fit for the dataset at hand due to the potential issue of high cardinality among categorical variables, which if one hot encoded would lead to p \> n (variables \> observations)
Therefore, we grouped the variables with low frequency into "Others" before one hot encoding them. Thereafter used forward selection to select regressors. The forward selection process found a model that contained 82 regressors out of which half weren't statistically significant, therefore thrown out to reduce noise as well as the risk of overfitting.

**Model Variants Tested** 

In total seven variations of the linear regression model were estimated to evaluate performance, namely:

-   Linear-linear
-   Log-linear
-   Log-log
-   Multiple linear regression with only 5 regressors (house size, land size, baths, beds and sale frequency)
-   Interaction between house size and land size
-   Polynomial term for land size
-   Combined approach - Interaction term as well as polynomial term

Out of the above listed models the first three(Linear-linear, Log-linear, and Log-log) were estimated under two different transformations of the data-random sampling & stratified sampling. Among these, the log-log model demonstrated the best performance under both data. However, an analysis of the residual plots under random sampling revealed that the residuals were not randomly distributed. This issue was addressed when stratified sampling technique was applied, the residuals now seemed to have a roughly constant variance. Therefore, the model with stratified was chosen as the best one, even through the R-squared value was slightly higher with the random sampling (60% with random sampling vs 58% with stratified). An analysis of the Q-Q plots showed the residuls cclosely followed the dashed line except the tails on either side which exhibited notable deviations, suggesting the presence of extreme outliers, therefore model is expected to be impacted in case of predictions related to extreme values(Luxury houses).

**Log-Log Model Performance Metrics**

The performance of the log-log linear regression model was evaluated using standard metrics as represented below -

| Metric                         | Value           |
|--------------------------------|-----------------|
| Mean Absolute Error (MAE)      | 187,846.8       |
| Mean Squared Error (MSE)       | 188,307,816,638 |
| Root Mean Squared Error (RMSE) | 433,944.5       |
| R-Squared                      | 53.71%          |

**Results**

RMSE: On average, the model exhibits a deviation of \$433,944.5 per prediction. The RMSE value of 433,944.5 is considered acceptable given that the price range of the properties in the dataset is in the millions.

MSE: The high value of the MSE suggests that outliers are significantly influencing the results,which consistent the observations from the Q-Q plots.

R-Squared: The model explains 53.71% variability seen in the target value.

**Comparison to Benchmark Values**

Studies in the real estate domain indicate that values of R-squared typically range between 0.40 and 0.80. Simpler models applied to high-variance datasets often yield values in the lower range. For real estate models in expensive markets such as New York City or San Francisco, RMSE greater than \$100,000 are common due to high property values. In light of these benchmarks, the performance of the baseline linear regression model aligns with expectations for real estate price prediction using datasets with significant variance.


### Model: XGBoost
XG Boost or Xtreme Gradient boosting is an ensemble learning technique i.e. it combines the predictions of multiple individual model to build a predictive model. Itâ€™s ability to handle complex relationships in data was the reason, it was chosen to 
model real estate price predictions.
The development of the XGBoost model for predicting real estate prices followed a structured and iterative approach aimed at improving predictive accuracy and model performance. The process began by building a baseline model that achieved an R-squared
score of 60%. This initial model served as a benchmark for subsequent optimizations.
To enhance the model's performance, we employed cross-validation to evaluate model stability and hyperparameter tuning to refine its predictive capacity. 

Two distinct methods for hyperparameter tuning were applied:

**Random Search:** This approach involved exploring a wide range of hyperparameter combinations randomly within defined bounds. 
**Grid Search:** This systematic method involved testing all possible combinations of predefined hyperparameter values.  
Grid search consistently produced models with the lowest Root Mean Square Error (RMSE), outperforming those optimized through random search. Therefore, the final model was built using the hyperparameter configuration derived from the grid search method.

The performance of the final XGBoost model is represented below -


| Metric                         | Value           |
|--------------------------------|-----------------|
| Mean Absolute Error (MAE)      | 164636.4        |
| Mean Squared Error (MSE)       | 173634154264    |
| Root Mean Squared Error (RMSE) | 416694.3        |
| R-Squared                      | 62.56%          |

**Results**

RMSE: On average, the model exhibits a deviation of \416694.3 per prediction which is a slight improvement as compared to linear regression. 

R-Squared: The model explains 62.56% variability seen in the target value.

**Comparison to Benchmark Values**
Typical RMSE values for XGBoost in real estate datasets can range from $20,000 to over $50,000 depending on data scale, while R-squared
 values often exceed 0.85 in well-optimized models. Therefore, the above estimated model is not upto par with the benchmark values.


## Evaluation

| Model             | Mean Absolute Error (MAE) | Mean Squared Error (MSE) | Root Mean Squared Error (RMSE) | R-Squared |
|---------------|--------------|-------------------|------------|------------|
| Linear Regression | 187,846.8                 | 188,307,816,638          | 433,944.5                      | 53.71%    |
| XGBoost           |  164636.4                 | 173634154264             | 416694.3                       |  62.56%   |
|                   |                           |                          |                                |           |
|                   |                           |                          |                                |           |

## Evaluation 
